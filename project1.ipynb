{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWGN 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def awgn_(input, dB_snr):\n",
    "    snr = 10**(dB_snr/10)\n",
    "    signal_power = 1\n",
    "    awgn_power = signal_power / snr\n",
    "    # 텐서 계산을 위해 텐서 타입으로 변환\n",
    "    awgn_power_tensor = torch.tensor(awgn_power, dtype=torch.float32)\n",
    "    awgn = torch.sqrt(awgn_power_tensor / 2)*(\n",
    "        torch.randn_like(input, dtype=torch.float32)+1j*torch.randn_like(input, dtype=torch.float32)\n",
    "    )\n",
    "    return input + awgn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1번 프로젝트\n",
    "`tr_qpsk.csv`를 이용하여 딥러닝 기반의 QPSK 복조 (Decoder)를 학습한다.\n",
    "이후 `te_qpsk.csv` 파일을 이용하여 정확도가 80% 이상인 모델을 사용하고자 한다.\n",
    "이때 Ground Truth는 `*_dec.csv` 파일을 사용하여 지도학습을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QPSK Decoder Model (CNN)\n",
    "class QPSKDemodulationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QPSKDemodulationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 4)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500000, 2]) torch.Size([500000, 1, 4])\n",
      "torch.Size([100000, 2]) torch.Size([100000, 1])\n"
     ]
    }
   ],
   "source": [
    "# Training Set 준비\n",
    "train_df = pd.read_csv('./data/tr_qpsk.csv', header=None)\n",
    "# 복소수 형태로 변환\n",
    "train_df[0] = train_df[0].str.replace('i', 'j')  # 'i'를 'j'로 변경 (Python 복소수 표기법에 맞춤)\n",
    "train_complex_numbers = train_df[0].apply(lambda x: complex(x))\n",
    "\n",
    "# 실수부와 허수부 분리\n",
    "train_qpsk_real_parts = train_complex_numbers.apply(lambda x: x.real)\n",
    "train_qpsk_imag_parts = train_complex_numbers.apply(lambda x: x.imag)\n",
    "\n",
    "# Ground Truth (dec)\n",
    "dec = np.loadtxt('./data/tr_dec.csv', delimiter=',')\n",
    "# DataFrame 생성\n",
    "train_df = pd.DataFrame({'Real': train_qpsk_real_parts, \n",
    "                         'Imaginary': train_qpsk_imag_parts, \n",
    "                         'dec': dec})\n",
    "\n",
    "# Test Set 준비\n",
    "test_df = pd.read_csv('./data/te_qpsk.csv', header=None)\n",
    "test_df[0] = test_df[0].str.replace('i', 'j')\n",
    "test_complex_numbers = test_df[0].apply(lambda x: complex(x))\n",
    "\n",
    "test_qpsk_real_parts = test_complex_numbers.apply(lambda x: x.real)\n",
    "test_qpsk_imag_parts = test_complex_numbers.apply(lambda x: x.imag)\n",
    "dec = np.loadtxt('./data/te_dec.csv', delimiter=',')\n",
    "\n",
    "test_df = pd.DataFrame({'Real': test_qpsk_real_parts, \n",
    "                        'Imaginary': test_qpsk_imag_parts, \n",
    "                        'dec': dec})\n",
    "\n",
    "# PyTorch 텐서로 변환\n",
    "X_train = torch.tensor(train_df[['Real','Imaginary']].values, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_df[['dec']].values, dtype=torch.long)\n",
    "# Output이 0,1,2,3이므로 one-hot encoding을 수행 (Softmax 사용)\n",
    "y_train = F.one_hot(y_train, 4).float()\n",
    "print(X_train.shape, y_train.shape)\n",
    "X_test = torch.tensor(test_df[['Real','Imaginary']].values, dtype=torch.float32)\n",
    "y_test = torch.tensor(test_df[['dec']].values, dtype=torch.long)\n",
    "# y_test_encode = F.one_hot(y_test, 4).fl/oat()\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kyounghwan-Kim\\anaconda3\\envs\\space-search\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 6.8016\n",
      "Epoch 2/10, Loss: 0.0006\n",
      "Epoch 3/10, Loss: 0.0001\n",
      "Epoch 4/10, Loss: 0.0000\n",
      "Epoch 5/10, Loss: 0.0000\n",
      "Epoch 6/10, Loss: 0.0000\n",
      "Epoch 7/10, Loss: 0.0000\n",
      "Epoch 8/10, Loss: 0.0000\n",
      "Epoch 9/10, Loss: 0.0000\n",
      "Epoch 10/10, Loss: 0.0000\n",
      "Test Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "model = QPSKDemodulationModel()\n",
    "criterion = nn.MSELoss()  # 손실 함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size][:,0]  # one-hot encoding에서 첫 번째 열 선택\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "# 테스트\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    _, predicted = torch.max(test_outputs, 1)  # 가장 높은 확률의 클래스 선택\n",
    "\n",
    "    accuracy = accuracy_score(y_test.numpy(), predicted.numpy())\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyounghwan-Kim\\AppData\\Local\\Temp\\ipykernel_25360\\2935096941.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_noise_tensor = torch.stack([torch.tensor(X_test_real_parts), torch.tensor(X_test_imag_parts)], dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 62\u001b[0m\n\u001b[0;32m     58\u001b[0m snr_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m11\u001b[39m)  \u001b[38;5;66;03m# 0 dB부터 10 dB까지\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# BER 평가 및 그래프 작성\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[43mevaluate_and_plot_ber\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnr_range\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 51\u001b[0m, in \u001b[0;36mevaluate_and_plot_ber\u001b[1;34m(model, X_test, y_test, snr_range)\u001b[0m\n\u001b[0;32m     49\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# BER 계산\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     ber \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_ber\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_bits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     ber_values\u001b[38;5;241m.\u001b[39mappend(ber)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# BER 그래프 작성\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36mcalculate_ber\u001b[1;34m(original_bits, predicted_bits)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_ber\u001b[39m(original_bits, predicted_bits):\n\u001b[1;32m----> 6\u001b[0m     errors \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43moriginal_bits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredicted_bits\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m      7\u001b[0m     ber \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;241m/\u001b[39m original_bits\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ber\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "# BER 그래프\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# BER 계산 함수\n",
    "def calculate_ber(original_bits, predicted_bits):\n",
    "    errors = (original_bits != predicted_bits).sum().item()\n",
    "    ber = errors / original_bits.numel()\n",
    "    return ber\n",
    "\n",
    "# BER 그래프 작성 함수\n",
    "def plot_ber(snr_values, ber_values):\n",
    "    \"\"\"\n",
    "    SNR 값과 BER 값을 사용해 semilogy 그래프를 그리는 함수\n",
    "    \n",
    "    Parameters:\n",
    "    - snr_values: SNR 값들의 리스트 또는 numpy 배열 (X축 값)\n",
    "    - ber_values: BER 값들의 리스트 또는 numpy 배열 (Y축 값)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.semilogy(snr_values, ber_values, marker='o', linestyle='-', linewidth=2, markersize=8)\n",
    "    plt.title(\"BER vs SNR (Log Scale)\", fontsize=14)\n",
    "    plt.xlabel(\"SNR (dB)\", fontsize=12)\n",
    "    plt.ylabel(\"Bit Error Rate (BER)\", fontsize=12)\n",
    "    plt.grid(True, which=\"both\", linestyle='--', linewidth=0.5)\n",
    "    plt.minorticks_on()\n",
    "    plt.show()\n",
    "\n",
    "# SNR에 따른 BER 계산 및 그래프 작성\n",
    "def evaluate_and_plot_ber(model, X_test, y_test, snr_range):\n",
    "    ber_values = []\n",
    "    for snr_db in snr_range:\n",
    "        # 복소수로 변환\n",
    "        X_test_complex = X_test[:, 0] + 1j*X_test[:, 1]\n",
    "        # awgn 추가\n",
    "        X_test_noise = awgn_(X_test_complex, snr_db)\n",
    "        # 실수부와 허수부 분리\n",
    "        X_test_real_parts = X_test_noise.real\n",
    "        X_test_imag_parts = X_test_noise.imag\n",
    "        # 텐서로 변환\n",
    "        X_test_noise_tensor = torch.stack([torch.tensor(X_test_real_parts), torch.tensor(X_test_imag_parts)], dim=1)\n",
    "        # 복조 수행\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = model(X_test_noise_tensor)\n",
    "            _, predicted_bits = torch.max(predictions, 1)\n",
    "        # 정수 -> 비트 변환\n",
    "        predicted_bits = [format(i.item(), '02b') for i in predicted_bits]\n",
    "        print(type(predicted_bits[0]))\n",
    "        y_test = y_test.view(-1, 1)\n",
    "        # BER 계산\n",
    "        ber = calculate_ber(y_test, predicted_bits)\n",
    "        ber_values.append(ber)\n",
    "\n",
    "    # BER 그래프 작성\n",
    "    plot_ber(snr_range, ber_values)\n",
    "\n",
    "# SNR 범위 설정\n",
    "snr_range = range(0, 11)  # 0 dB부터 10 dB까지\n",
    "\n",
    "# BER 평가 및 그래프 작성\n",
    "\n",
    "evaluate_and_plot_ber(model, X_test, y_test, snr_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문 정리\n",
    "1. AWGN 함수 오류\n",
    "- 제공해주신 함수에 오류가 있는데, 수정해서 사용해도 괜찮은 건지\n",
    "2. AWGN 함수는 학습 말고 그래프 그릴때만 사용하는 건지 (시뮬레이션 노이즈 넣는 걸로 알고 있음)\n",
    "\n",
    "3. BER 계산할 때 비트 연산으로 해야하는지?\n",
    "- 지금 Softmax로 정수값을 원핫인코딩해서 처리하고 있는데, BER 계산할 때 te_bits 파일은 이용하되, bit를 정수로 변환해서 계산해도 되는건지..?\n",
    "4. 학습 돌려보니깐 정확도가 100%인데,, Overfitting 문제?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "space-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
